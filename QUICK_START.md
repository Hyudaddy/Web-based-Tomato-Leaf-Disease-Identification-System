# âš¡ Quick Start - Model Retraining

## ğŸ¯ Your Setup
- **Option:** C (Balanced)
- **Device:** Intel Core i3 (CPU)
- **Time:** 30-60 minutes
- **Goal:** Better accuracy on low-quality images

---

## ğŸš€ Three Simple Steps

### Step 1: Check Everything (5 min)
```bash
python check_and_prepare.py
```
**Expected output:** `âœ… ALL CHECKS PASSED! Ready to train!`

---

### Step 2: Analyze Dataset (5 min)
```bash
python analyze_dataset.py
```
**What to look for:**
- All 11 classes present
- Each class has images
- Balanced distribution

---

### Step 3: Train Model (30-60 min)
```bash
python train_model_optimized.py
```

**What happens:**
- Loads full dataset
- Trains for up to 35 epochs
- Saves best model automatically
- Shows progress each epoch

**Expected final output:**
```
âœ… Final Validation Accuracy: 88-92%
âœ… New model saved at: C:\Users\HYUDADDY\Desktop\TLDI_system\backend\trained_model_fito.h5
```

---

## âœ… After Training

1. **Restart your backend API**
2. **Test with low-quality images**
3. **Check if "cannot identify" results decreased**

---

## ğŸ“Š What's Different

| Aspect | Before | After |
|--------|--------|-------|
| Image Size | 128x128 | 192x192 |
| Batch Size | 32 | 20 |
| Epochs | 20 | 35 |
| Learning Rate | 0.001 | 0.0005 |
| Augmentation | Basic | Enhanced (brightness, contrast) |

---

## ğŸ’¡ Key Improvements

âœ… Handles low-quality images better  
âœ… Better feature extraction (larger images)  
âœ… More training iterations (35 epochs)  
âœ… Brightness/contrast adjustments for poor lighting  
âœ… Early stopping prevents overfitting  

---

## âš ï¸ If Something Goes Wrong

**Slow training?**
- Normal on CPU - just wait
- Or reduce BATCH_SIZE to 16 in script

**Out of memory?**
- Reduce BATCH_SIZE to 16
- Or reduce IMG_SIZE to 160

**Accuracy didn't improve?**
- Check dataset balance: `python analyze_dataset.py`
- Might need more training data

---

## ğŸ“ Files

- `train_model_optimized.py` â† Main script
- `analyze_dataset.py` â† Check dataset
- `check_and_prepare.py` â† Pre-flight check
- `TRAINING_GUIDE.md` â† Detailed guide
- `training_history.json` â† Results (after training)

---

## ğŸ“ Understanding Progress

```
Epoch 1/35
1000/1000 [==============================] - 120s - loss: 0.8234 - accuracy: 0.7234 - val_loss: 0.6234 - val_accuracy: 0.8123
```

**Good signs:**
- âœ… val_accuracy increases each epoch
- âœ… val_loss decreases
- âœ… No sudden jumps

**Bad signs:**
- âŒ val_accuracy stays same
- âŒ val_loss increases
- âŒ Training crashes

---

## ğŸ”„ Workflow

```
Run check_and_prepare.py
         â†“
Run analyze_dataset.py
         â†“
Run train_model_optimized.py (30-60 min)
         â†“
Check training_history.json
         â†“
Restart backend API
         â†“
Test with low-quality images
```

---

**Ready? Let's go! ğŸš€**

```bash
python check_and_prepare.py
```
